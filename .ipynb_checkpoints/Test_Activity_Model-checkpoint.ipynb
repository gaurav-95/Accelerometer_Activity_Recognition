{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mdumM_l2x0n"
   },
   "source": [
    "## Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tU6J52vWBy8t"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "from datetime import timedelta\n",
    "from tensorflow import keras\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xyz=pd.read_csv('C:/Users/Gaurav/Downloads/Accelerometer/acc_act_sw_01-04-2021.csv')\n",
    "# xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/04/2021%2021:24:18\n",
      "26/04/2021%2021:24:23\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now(tz=gettz('Asia/Kolkata'))\n",
    "prev = now - timedelta(seconds=5)\n",
    "\n",
    "## Timezone change\n",
    "#print(now)\n",
    "\n",
    "# 18:44:00 and 18:57:00 (walking)\n",
    "# 19:03:00 and 19:08:00 (sitting)\n",
    "\n",
    "from_time = prev.strftime(\"%d/%m/%Y\") + \"%20\" + prev.strftime(\"%H:%M:%S\")\n",
    "print(from_time)\n",
    "\n",
    "to_time = now.strftime(\"%d/%m/%Y\")+ \"%20\" + now.strftime(\"%H:%M:%S\")\n",
    "print(to_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ID\n",
    "# Yuvraj: 605452ebe6794b000413a860\n",
    "# Jai: 60645822879db200046051de\n",
    "# Gourab: 607c1911676b1700046ae8ea\n",
    "\n",
    "response = requests.get(\"https://apiserverparentprotect.herokuapp.com/accelerometer-data?secret_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiJkZWJhbmphbiIsImlhdCI6MTYxNjY0NjA3OH0.Tfyog7lHPADpickUc1itaxdC_fs4_eAxLQDY3G9C5Z4&type=accelerometer&dateFrom=\"+from_time+\"&dateTo=\"+to_time+\"&userID=607c1911676b1700046ae8ea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get user list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'secret_token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjp7Il9pZCI6IjYwNWM0YWQ3NjVmNzdiNDk4NGFiZjQ3YiIsImVtYWlsIjoiZGViQGdtYWlsLmNvbSIsInByb3ZpZGVyIjoibG9jYWwifSwiaWF0IjoxNjE2NjcwOTIzfQ.gT2qntKlqMThfrI562tLvDByEy_u-W5PC-NyXlmr2yc', 'timestamp': '26/04/2021 21:24:18'}\n",
      "<Response [200]>\n",
      "{'status': 1, 'message': 'success', 'data': {'users': [], 'date': '2021-04-26T21:24:18.000Z'}}\n"
     ]
    }
   ],
   "source": [
    "timestamp = prev.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "secret_token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjp7Il9pZCI6IjYwNWM0YWQ3NjVmNzdiNDk4NGFiZjQ3YiIsImVtYWlsIjoiZGViQGdtYWlsLmNvbSIsInByb3ZpZGVyIjoibG9jYWwifSwiaWF0IjoxNjE2NjcwOTIzfQ.gT2qntKlqMThfrI562tLvDByEy_u-W5PC-NyXlmr2yc\"\n",
    "\n",
    "user_url = \"https://apiserverparentprotect.herokuapp.com/get-active-users\"\n",
    "\n",
    "user_list = {\"secret_token\": secret_token,  \"timestamp\": timestamp}\n",
    "print(user_list)\n",
    "response = requests.post(user_url , json=user_list)\n",
    "\n",
    "print(response)\n",
    "user=response.json()\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4360f9fc093b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccelero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "accelero = response.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=len(accelero[\"data\"])\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(accelero)\n",
    "print(type(accelero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0,tot):\n",
    "    accelero['data'][i].pop(0)\n",
    "#     accelero['accelerometer_data_array'][i].pop(119)\n",
    "#     accelero['accelerometer_data_array'][i].pop(118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accelero['accelerometer_data_array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(List_2D):\n",
    "    List_flat=[]\n",
    "    for i in range(len(List_2D)): #Traversing through the main list\n",
    "        for j in range (len(List_2D[i])): #Traversing through each sublist\n",
    "            List_flat.append(List_2D[i][j])\n",
    "    return List_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a=flatten(accelero['accelerometer_data_array'])\n",
    "#print(type(a[0]))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "v = np.array(a[0::2], float)\n",
    "v = v*0.0078125 ##(1/128)\n",
    "print(v)\n",
    "print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(data.tail(1).index,\n",
    "#         inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = v[0::3]\n",
    "y = v[1::3]\n",
    "z = v[2::3]\n",
    "print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(17, 4))\n",
    "plt.plot(x)\n",
    "plt.plot(y)\n",
    "plt.plot(z)\n",
    "#plt.plot(data['v*0.008'].values)\n",
    "#plt.plot(data['g*0.016'].values)\n",
    "#plt.plot(data['v*g'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xyz = pd.DataFrame(list(zip(x, y, z)),\n",
    "               columns =['x', 'y', 'z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sleUu8fO2uy5"
   },
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgHQBQ5wkU8H"
   },
   "outputs": [],
   "source": [
    "# def prepare(data):\n",
    "#     data=data[[\"x\",\"y\",\"z\"]]\n",
    "\n",
    "#     print(data.isnull().sum())\n",
    "#     data = data.dropna()\n",
    "#     print(data.isnull().sum())\n",
    "\n",
    "#     scaler2 = MinMaxScaler()\n",
    "#     X = scaler2.fit_transform(data)\n",
    "  \n",
    "#     scaled_X = pd.DataFrame(data = X, columns = ['x', 'y', 'z'])\n",
    "  \n",
    "#     return scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv2Hqb9woLDu"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# scaled_X=prepare(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(17, 4))\n",
    "# plt.plot(scaled_X['x'])\n",
    "# plt.plot(scaled_X['y'])\n",
    "# plt.plot(scaled_X['z'])\n",
    "# #plt.plot(data['v*0.008'].values)\n",
    "# #plt.plot(data['g*0.016'].values)\n",
    "# #plt.plot(data['v*g'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av7d6ZvzsQi2"
   },
   "outputs": [],
   "source": [
    "#Framing into colvolutions\n",
    "def get_frames(df, frame_size, hop_size):\n",
    "\n",
    "    N_FEATURES = 3\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(0, len(df) - frame_size, hop_size):\n",
    "        x = df['x'].values[i: i + frame_size]\n",
    "        y = df['y'].values[i: i + frame_size]\n",
    "        z = df['z'].values[i: i + frame_size]\n",
    "        \n",
    "        frames.append([x, y, z])\n",
    "  \n",
    "    # Bring the segments into a better shape\n",
    "    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
    "\n",
    "    return frames#, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4jdlzG2seax"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "frame_size = 120\n",
    "hop_size = frame_size*1\n",
    "X = get_frames(xyz, frame_size, hop_size)#, timestamps\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_iter=len(timestamps)\n",
    "# print(t_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(min(timestamps[0]))\n",
    "# print(max(timestamps[0]))\n",
    "# print(min(timestamps[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_frame=[]\n",
    "# for i in range(0, t_iter):\n",
    "#     t_frame.append(min(timestamps[i]))\n",
    "#     t_frame.append(max(timestamps[i]))\n",
    "# #print(t_frame)\n",
    "# print(len(t_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSngCV9HtwXf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#reshaping\n",
    "a=X.shape\n",
    "a = a + (1,)\n",
    "X = X.reshape(a)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zpkXS8llkAw"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = keras.models.load_model(\"C:/Users/Gaurav/Downloads/Accelerometer/Testing_Folder/activity_detectv9.h5\")\n",
    "#activity_detectv7.h5\n",
    "\n",
    "prediction = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy\n",
    "from numpy import argmax\n",
    "summed = numpy.sum(prediction, axis=0)\n",
    "print(summed)\n",
    "label_val = argmax(summed)\n",
    "print(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if label_val == 0:\n",
    "    print(\"running\")\n",
    "elif label_val == 1:\n",
    "    print(\"sitting\")\n",
    "elif label_val == 2:\n",
    "    print(\"walking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Docker hosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": X.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/activity:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "pred=[np.argmax(predictions[p]) for p in range(len(predictions)) ]\n",
    "print(\"Predictions: \",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if pred[0] == 0:\n",
    "    print(\"running\")\n",
    "elif pred[0] == 1:\n",
    "    print(\"sitting\")\n",
    "elif pred[0] == 2:\n",
    "    print(\"walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering time stamps + predictions in a dataframe for clear analysis\n",
    "analyze = pd.DataFrame()\n",
    "# analyze[\"start\"]=t_frame[::2]\n",
    "# analyze[\"stop\"]=t_frame[1::2]\n",
    "analyze[\"prediction\"]=prediction\n",
    "print(analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze.to_csv('analyze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Gaurav/Downloads/Accelerometer/acc_walking_sw_01-04-2021_1938-2010.csv')\n",
    "df.drop('Unnamed: 0', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = df.merge(analyze, how='inner', left_on='time', right_on='stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common.to_csv('compare.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test_Fall_Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
